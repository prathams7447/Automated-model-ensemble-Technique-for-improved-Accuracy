{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e59aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy pandas matplotlib seaborn scikit-learn xgboost lightgbm imbalanced-learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier,GradientBoostingRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from scipy.stats import zscore\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv(\"creditcard.csv\", skiprows=lambda i: i > 0 and np.random.rand() > 0.5)\n",
    "print(\"Dataset Loaded\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72eb2a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Missing Values (if any)\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "df.iloc[:, :-1] = num_imputer.fit_transform(df.iloc[:, :-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdbee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Detection & Removal (Z-score)\n",
    "z_scores = np.abs(zscore(df.drop(columns=['Class'])))\n",
    "df = df[(z_scores < 3).all(axis=1)]\n",
    "print(\"Outliers Removed\")\n",
    "\n",
    "# Remove Duplicates\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1adf51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature Engineering: Log Transformation on Amount\n",
    "df['log_amount'] = np.log1p(df['Amount'])\n",
    "df.drop(['Amount'], axis=1, inplace=True)\n",
    "\n",
    "# Feature Scaling (Standardization & MinMax Scaling)\n",
    "scaler = StandardScaler()\n",
    "df.iloc[:, :-2] = scaler.fit_transform(df.iloc[:, :-2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2196acce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality Reduction using PCA\n",
    "pca = PCA(n_components=10)\n",
    "X_pca = pca.fit_transform(df.drop(columns=['Class']))\n",
    "\n",
    "# Splitting Data into Train & Test\n",
    "X = X_pca\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Handling Class Imbalance using SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03537c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Model Selection\n",
    "rf = RandomForestClassifier(n_estimators=50, n_jobs=1, random_state=42)\n",
    "xgb = XGBClassifier(objective='binary:logistic', n_jobs=1, random_state=42, n_estimators=50)\n",
    "stacking_classifier = StackingClassifier(\n",
    "    estimators=[('rf', rf), ('xgb', xgb)],\n",
    "    final_estimator=GradientBoostingClassifier(n_estimators=50),\n",
    "    n_jobs=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa2c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(stacking_classifier, X_train, y_train, cv=kf, scoring='accuracy', n_jobs=1)\n",
    "print(f\"Cross-Validation Accuracy: {np.mean(cv_scores):.4f}\")\n",
    "\n",
    "# Train Final Model\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "y_pred = stacking_classifier.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78549bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6001f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Fraud', 'Fraud'], yticklabels=['Not Fraud', 'Fraud'])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7667d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b53d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the scaler and PCA transformer\n",
    "with open(\"scaler.pkl\", \"wb\") as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "\n",
    "with open(\"pca_transformer.pkl\", \"wb\") as pca_file:\n",
    "    pickle.dump(pca, pca_file)\n",
    "\n",
    "with open(\"fraud_detection_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(stacking_classifier, model_file)\n",
    "\n",
    "print(\" File Saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
